{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>cvemun</th>\n",
       "      <th>mydate</th>\n",
       "      <th>fam</th>\n",
       "      <th>ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1001</td>\n",
       "      <td>171.0</td>\n",
       "      <td>8353.0</td>\n",
       "      <td>34921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1002</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1011</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1313</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>171.0</td>\n",
       "      <td>7579.0</td>\n",
       "      <td>31412.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  quarter  cvemun  mydate     fam      ind\n",
       "0  2002.0      4.0    1001   171.0  8353.0  34921.0\n",
       "1  2002.0      4.0    1002   171.0     1.0      5.0\n",
       "2  2002.0      4.0    1011   171.0     1.0      3.0\n",
       "3  2002.0      4.0    1313   171.0     1.0      2.0\n",
       "4  2002.0      4.0    2001   171.0  7579.0  31412.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bosch_rollout = pd.read_stata(\"benef_SP_2002_2009.dta\")\n",
    "bosch_rollout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/834781427.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  year = row[0]\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/834781427.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cve_mun = row[2]\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/834781427.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  people_enrolled = row[5]\n"
     ]
    }
   ],
   "source": [
    "cve_mun_ls, year_col_ls = [], []\n",
    "cve_mun_added = set()\n",
    "\n",
    "for index, row in bosch_rollout.iterrows():\n",
    "  year = row[0]\n",
    "  cve_mun = row[2]\n",
    "  people_enrolled = row[5]\n",
    "  if cve_mun not in cve_mun_added:\n",
    "    if people_enrolled > 9:\n",
    "        cve_mun_added.add(cve_mun)\n",
    "        cve_mun_ls.append(cve_mun)\n",
    "        year_col_ls.append(year)\n",
    "\n",
    "\n",
    "#fix exact rollout\n",
    "#2002, 2003, 2004 -> 1\n",
    "#2005, 2006, 2007, 2008 -> 2\n",
    "#2009 -> 3\n",
    "year_col_ls = np.array(year_col_ls)\n",
    "categories = np.zeros_like(year_col_ls)\n",
    "\n",
    "categories[(year_col_ls >= 2002) & (year_col_ls <= 2004)] = 2\n",
    "categories[(year_col_ls >= 2005) & (year_col_ls <= 2008)] = 3\n",
    "categories[year_col_ls == 2009] = 4\n",
    "\n",
    "categories = categories.tolist()\n",
    "# rollout_df = pd.DataFrame({'cvemun': cve_mun_ls, 'year': year_col_ls, 'group': categories})\n",
    "# rollout_df.head()\n",
    "cve_mun_to_treatment_group = dict(zip(cve_mun_ls, categories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folio</th>\n",
       "      <th>ls</th>\n",
       "      <th>rel</th>\n",
       "      <th>reh</th>\n",
       "      <th>edo</th>\n",
       "      <th>mpio</th>\n",
       "      <th>loc</th>\n",
       "      <th>control</th>\n",
       "      <th>estrato</th>\n",
       "      <th>edad</th>\n",
       "      <th>id_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6299000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6293000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6281000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6312000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6314000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3138.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       folio   ls   rel  reh  edo  mpio   loc  control  estrato  edad  id_loc\n",
       "0  6299000.0  1.0  20.0  1.0  3.0   1.0  38.0     20.0      4.0  73.0  3138.0\n",
       "1  6293000.0  2.0  20.0  1.0  3.0   1.0  38.0     20.0      4.0  49.0  3138.0\n",
       "2  6281000.0  2.0  20.0  1.0  3.0   1.0  38.0     20.0      4.0  41.0  3138.0\n",
       "3  6312000.0  1.0  20.0  1.0  3.0   1.0  38.0     20.0      4.0  32.0  3138.0\n",
       "4  6314000.0  2.0  20.0  1.0  3.0   1.0  38.0     20.0      4.0  55.0  3138.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mflx_mun_02 = pd.read_stata(\"hh02dta_all/hh02dta_bc/c_portad.dta\")\n",
    "mflx_mun_02.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8296"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def output_cve_mun(estado, municipio):\n",
    "  estado = str(int(estado))\n",
    "  municipio = str(int(municipio))\n",
    "\n",
    "  if len(municipio) < 2:\n",
    "    municipio = \"0\" + municipio\n",
    "  if len(municipio) < 3:\n",
    "    municipio = \"0\" + municipio\n",
    "  \n",
    "  return int(estado + municipio)\n",
    "\n",
    "# stripped_folio = []\n",
    "\n",
    "#cve_mun = []\n",
    "household02_tocvemun_dict = {}\n",
    "\n",
    "#TODO: fix this since only takes into account 02? rethink\n",
    "for index, row in mflx_mun_02.iterrows():\n",
    "  if not pd.isna(row['folio']):\n",
    "    trimmed_folio = int(str(int(row['folio']))[:-3])\n",
    "    get_cve_mun = output_cve_mun(row['edo'], row['mpio'])\n",
    "    household02_tocvemun_dict[trimmed_folio] = get_cve_mun\n",
    "\n",
    "\n",
    "# mflx_mun_02['trimmed_number'] = mflx_mun_02['folio'].apply(lambda x: int(str(int(x))[:-3]) if not pd.isna(x) else np.nan)\n",
    "# for index, row in mflx_mun_02.iterrows():\n",
    "#     if not pd.isna(row['edo']) and not pd.isna(row['mpio']):\n",
    "#         get_cve_mun_result = output_cve_mun(row['edo'], row['mpio'])\n",
    "#         household02_tocvemun_dict[]\n",
    "#         cve_mun.append(get_cve_mun_result)\n",
    "#     else:\n",
    "#         cve_mun.append(np.nan)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#create cve column (edo + 3 digit str)\n",
    "#created stripped folio\n",
    "#maybe put both into dict\n",
    "#generate hours worked, later\n",
    "\n",
    "#how do you deal with people that change households, move places?\n",
    "len(household02_tocvemun_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folio</th>\n",
       "      <th>ls</th>\n",
       "      <th>pid_link</th>\n",
       "      <th>tb02_1</th>\n",
       "      <th>tb03</th>\n",
       "      <th>tb04</th>\n",
       "      <th>tb05</th>\n",
       "      <th>tb06</th>\n",
       "      <th>tb07</th>\n",
       "      <th>tb08</th>\n",
       "      <th>...</th>\n",
       "      <th>tb57</th>\n",
       "      <th>tb57s</th>\n",
       "      <th>tb58_59_cmo</th>\n",
       "      <th>tb60</th>\n",
       "      <th>tb61</th>\n",
       "      <th>tb62</th>\n",
       "      <th>tb221_1</th>\n",
       "      <th>tb221_2</th>\n",
       "      <th>tb222_1</th>\n",
       "      <th>tb222_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000010AP00</td>\n",
       "      <td>01</td>\n",
       "      <td>000010AP0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000010AP00</td>\n",
       "      <td>02</td>\n",
       "      <td>000010AP0002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000010AP00</td>\n",
       "      <td>04</td>\n",
       "      <td>000010AP0004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000010AP00</td>\n",
       "      <td>06</td>\n",
       "      <td>000010AP0006</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000010BP03</td>\n",
       "      <td>02</td>\n",
       "      <td>000010AP0003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 248 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        folio  ls      pid_link  tb02_1  tb03  tb04  tb05  tb06  tb07  tb08  \\\n",
       "0  000010AP00  01  000010AP0001     1.0   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1  000010AP00  02  000010AP0002     1.0   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2  000010AP00  04  000010AP0004     1.0   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "3  000010AP00  06  000010AP0006     4.0   3.0   3.0   3.0   3.0   NaN   NaN   \n",
       "4  000010BP03  02  000010AP0003     1.0   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "   ...  tb57  tb57s  tb58_59_cmo  tb60  tb61  tb62  tb221_1  tb221_2  tb222_1  \\\n",
       "0  ...   NaN    NaN          NaN   NaN   NaN   NaN      NaN      NaN      NaN   \n",
       "1  ...   NaN    NaN          NaN   NaN   NaN   NaN      NaN      NaN      NaN   \n",
       "2  ...   2.0    NaN         12.0   6.0   3.0   NaN      NaN      NaN      NaN   \n",
       "3  ...   NaN    NaN          NaN   NaN   NaN   NaN      NaN      NaN      NaN   \n",
       "4  ...   NaN    NaN          NaN   NaN   NaN   NaN      NaN      NaN      NaN   \n",
       "\n",
       "   tb222_2  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  \n",
       "\n",
       "[5 rows x 248 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mflx_labor_09 = pd.read_stata(\"hh09dta_all/hh09dta_b3a/iiia_tb.dta\")\n",
    "mflx_labor_09.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folio</th>\n",
       "      <th>ls</th>\n",
       "      <th>pid_link</th>\n",
       "      <th>tb02_1</th>\n",
       "      <th>tb03</th>\n",
       "      <th>tb04</th>\n",
       "      <th>tb05</th>\n",
       "      <th>tb06</th>\n",
       "      <th>tb07</th>\n",
       "      <th>tb08</th>\n",
       "      <th>...</th>\n",
       "      <th>tb57_2</th>\n",
       "      <th>tb58_59_cmo</th>\n",
       "      <th>tb58_59_scian</th>\n",
       "      <th>tb60</th>\n",
       "      <th>tb61</th>\n",
       "      <th>tb62</th>\n",
       "      <th>tb221_1</th>\n",
       "      <th>tb221_2</th>\n",
       "      <th>tb222_1</th>\n",
       "      <th>tb222_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001000</td>\n",
       "      <td>01</td>\n",
       "      <td>0000100001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001000</td>\n",
       "      <td>02</td>\n",
       "      <td>0000100002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001003</td>\n",
       "      <td>01</td>\n",
       "      <td>0000100301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001003</td>\n",
       "      <td>02</td>\n",
       "      <td>0000100003</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00002000</td>\n",
       "      <td>02</td>\n",
       "      <td>0000200002</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      folio  ls    pid_link  tb02_1  tb03  tb04  tb05  tb06  tb07  tb08  ...  \\\n",
       "0  00001000  01  0000100001     1.0   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "1  00001000  02  0000100002     1.0   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "2  00001003  01  0000100301     1.0   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "3  00001003  02  0000100003     4.0   3.0   3.0   3.0   3.0   NaN   NaN  ...   \n",
       "4  00002000  02  0000200002     4.0   3.0   3.0   3.0   1.0   1.0   2.0  ...   \n",
       "\n",
       "   tb57_2  tb58_59_cmo  tb58_59_scian  tb60  tb61  tb62  tb221_1  tb221_2  \\\n",
       "0     NaN          NaN            NaN   NaN   NaN   NaN      NaN      NaN   \n",
       "1     NaN          NaN            NaN   NaN   NaN   NaN      NaN      NaN   \n",
       "2     NaN         14.0           71.0   3.0   3.0   NaN      NaN      NaN   \n",
       "3     NaN          NaN            NaN   NaN   NaN   NaN      NaN      NaN   \n",
       "4     NaN          NaN            NaN   NaN   NaN   NaN      NaN      NaN   \n",
       "\n",
       "   tb222_1  tb222_2  \n",
       "0      NaN      NaN  \n",
       "1      NaN      NaN  \n",
       "2      NaN      NaN  \n",
       "3      NaN      NaN  \n",
       "4      NaN      NaN  \n",
       "\n",
       "[5 rows x 241 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mflx_labor_05 = pd.read_stata(\"hh05dta_all/hh05dta_b3a/iiia_tb.dta\")\n",
    "mflx_labor_05.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tb02_1</th>\n",
       "      <th>tb03</th>\n",
       "      <th>tb04</th>\n",
       "      <th>tb05</th>\n",
       "      <th>tb06</th>\n",
       "      <th>tb07</th>\n",
       "      <th>tb08</th>\n",
       "      <th>tb09_1</th>\n",
       "      <th>tb09_2</th>\n",
       "      <th>tb10</th>\n",
       "      <th>...</th>\n",
       "      <th>tb24_26s_cmo</th>\n",
       "      <th>tb24_26s_scian</th>\n",
       "      <th>tb41_43p_cmo</th>\n",
       "      <th>tb41_43p_scian</th>\n",
       "      <th>tb41_43s_cmo</th>\n",
       "      <th>tb41_43s_scian</th>\n",
       "      <th>tb58_59_cmo</th>\n",
       "      <th>tb58_59_scian</th>\n",
       "      <th>tb24_26p_cmo</th>\n",
       "      <th>tb24_26p_scian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tb02_1  tb03  tb04  tb05  tb06  tb07  tb08  tb09_1  tb09_2  tb10  ...  \\\n",
       "0     1.0   NaN   NaN   NaN   NaN   NaN   NaN     NaN     NaN   NaN  ...   \n",
       "1     4.0   3.0   3.0   3.0   3.0   NaN   NaN     NaN     NaN   NaN  ...   \n",
       "2     3.0   3.0   3.0   3.0   3.0   NaN   NaN     NaN     NaN   NaN  ...   \n",
       "3     4.0   1.0   NaN   NaN   NaN   NaN   NaN     NaN     NaN   NaN  ...   \n",
       "4     9.0   3.0   3.0   3.0   3.0   NaN   NaN     NaN     NaN   NaN  ...   \n",
       "\n",
       "   tb24_26s_cmo  tb24_26s_scian  tb41_43p_cmo  tb41_43p_scian  tb41_43s_cmo  \\\n",
       "0           NaN             NaN           NaN             NaN           NaN   \n",
       "1           NaN             NaN           NaN             NaN           NaN   \n",
       "2           NaN             NaN           NaN             NaN           NaN   \n",
       "3           NaN             NaN           NaN             NaN           NaN   \n",
       "4           NaN             NaN           NaN             NaN           NaN   \n",
       "\n",
       "   tb41_43s_scian  tb58_59_cmo  tb58_59_scian  tb24_26p_cmo  tb24_26p_scian  \n",
       "0             NaN         54.0           23.0          55.0            93.0  \n",
       "1             NaN          NaN            NaN           NaN             NaN  \n",
       "2             NaN          NaN            NaN           NaN             NaN  \n",
       "3             NaN         82.0           81.0          81.0            81.0  \n",
       "4             NaN          NaN            NaN           NaN             NaN  \n",
       "\n",
       "[5 rows x 252 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mflx_labor_02 = pd.read_stata(\"hh02dta_all/hh02dta_b3a/iiia_tb.dta\")\n",
    "mflx_labor_02.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/4219106149.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_02['trimmed_folio'] = mflx_labor_02['folio'].apply(lambda x: int(str(int(x))[:-3]) if not pd.isna(x) else np.nan)\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/4219106149.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_02['cve_treatment'] = treatment_group_ls\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/4219106149.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_05['trimmed_folio'] = mflx_labor_05['folio'].apply(lambda x: int(str(x)[:-3]) if not pd.isna(x) else np.nan)\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/4219106149.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_05['cve_treatment'] = treatment_group_ls\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/4219106149.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_09['trimmed_folio'] = mflx_labor_09['folio'].apply(lambda x: int(str(x)[:-5]) if not pd.isna(x) else np.nan)\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/4219106149.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_09['cve_treatment'] = treatment_group_ls\n"
     ]
    }
   ],
   "source": [
    "mflx_labor_02['trimmed_folio'] = mflx_labor_02['folio'].apply(lambda x: int(str(int(x))[:-3]) if not pd.isna(x) else np.nan)\n",
    "treatment_group_ls = []\n",
    "\n",
    "for index, row in mflx_labor_02.iterrows():\n",
    "  trimmed_folio = row['trimmed_folio']\n",
    "  cve_mun = household02_tocvemun_dict.get(trimmed_folio)  # Get cve_mun from household02_tocvemun_dict\n",
    "  if cve_mun and cve_mun in cve_mun_to_treatment_group:\n",
    "      treatment_group = cve_mun_to_treatment_group[cve_mun]\n",
    "      treatment_group_ls.append(treatment_group)\n",
    "  else:\n",
    "      treatment_group_ls.append(np.NaN)\n",
    "\n",
    "mflx_labor_02['cve_treatment'] = treatment_group_ls\n",
    "\n",
    "\n",
    "\n",
    "mflx_labor_05['trimmed_folio'] = mflx_labor_05['folio'].apply(lambda x: int(str(x)[:-3]) if not pd.isna(x) else np.nan)\n",
    "treatment_group_ls = []\n",
    "\n",
    "for index, row in mflx_labor_05.iterrows():\n",
    "  trimmed_folio = row['trimmed_folio']\n",
    "  cve_mun = household02_tocvemun_dict.get(trimmed_folio)  # Get cve_mun from household02_tocvemun_dict\n",
    "  if cve_mun and cve_mun in cve_mun_to_treatment_group:\n",
    "      treatment_group = cve_mun_to_treatment_group[cve_mun]\n",
    "      treatment_group_ls.append(treatment_group)\n",
    "  else:\n",
    "      treatment_group_ls.append(np.NaN)\n",
    "\n",
    "mflx_labor_05['cve_treatment'] = treatment_group_ls\n",
    "\n",
    "\n",
    "\n",
    "mflx_labor_09['trimmed_folio'] = mflx_labor_09['folio'].apply(lambda x: int(str(x)[:-5]) if not pd.isna(x) else np.nan)\n",
    "treatment_group_ls = []\n",
    "\n",
    "for index, row in mflx_labor_09.iterrows():\n",
    "  trimmed_folio = row['trimmed_folio']\n",
    "  cve_mun = household02_tocvemun_dict.get(trimmed_folio)  # Get cve_mun from household02_tocvemun_dict\n",
    "  if cve_mun and cve_mun in cve_mun_to_treatment_group:\n",
    "      treatment_group = cve_mun_to_treatment_group[cve_mun]\n",
    "      treatment_group_ls.append(treatment_group)\n",
    "  else:\n",
    "      treatment_group_ls.append(np.NaN)\n",
    "\n",
    "mflx_labor_09['cve_treatment'] = treatment_group_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/3759383938.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_02[\"unique_id\"] = unique_id_02_ls\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/3759383938.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_05[\"unique_id\"] = unique_id_05_ls\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/3759383938.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_09[\"unique_id\"] = unique_id_09_ls\n"
     ]
    }
   ],
   "source": [
    "tracked = {}\n",
    "counter = 1\n",
    "\n",
    "#assigns unique integer ID to each folio-ls pair\n",
    "for index, row in mflx_labor_02.iterrows():\n",
    "  folio = int(row['trimmed_folio'])\n",
    "  id = int(row['ls'])\n",
    "  if folio in tracked:\n",
    "    if id not in tracked[folio]:\n",
    "      tracked[folio][id] = counter\n",
    "      counter += 1\n",
    "  elif folio not in tracked:\n",
    "    tracked[folio] = {}\n",
    "    tracked[folio][id] = counter\n",
    "    counter += 1\n",
    "\n",
    "for index, row in mflx_labor_05.iterrows():\n",
    "  folio = int(row['trimmed_folio'])\n",
    "  id = int(row['ls'])\n",
    "  if folio in tracked:\n",
    "    if id not in tracked[folio]:\n",
    "      tracked[folio][id] = counter\n",
    "      counter += 1\n",
    "  elif folio not in tracked:\n",
    "    tracked[folio] = {}\n",
    "    tracked[folio][id] = counter\n",
    "    counter += 1\n",
    "\n",
    "for index, row in mflx_labor_09.iterrows():\n",
    "  folio = int(row['trimmed_folio'])\n",
    "  id = int(row['ls'])\n",
    "  if folio in tracked:\n",
    "    if id not in tracked[folio]:\n",
    "      tracked[folio][id] = counter\n",
    "      counter += 1\n",
    "  elif folio not in tracked:\n",
    "    tracked[folio] = {}\n",
    "    tracked[folio][id] = counter\n",
    "    counter += 1\n",
    "\n",
    "#add unique id column\n",
    "unique_id_02_ls = []\n",
    "for index, row in mflx_labor_02.iterrows():\n",
    "  folio = int(row['trimmed_folio'])\n",
    "  id = int(row['ls'])\n",
    "  unique_id_02_ls.append(tracked[folio][id])\n",
    "mflx_labor_02[\"unique_id\"] = unique_id_02_ls\n",
    "\n",
    "unique_id_05_ls = []\n",
    "for index, row in mflx_labor_05.iterrows():\n",
    "  folio = int(row['trimmed_folio'])\n",
    "  id = int(row['ls'])\n",
    "  unique_id_05_ls.append(tracked[folio][id])\n",
    "mflx_labor_05[\"unique_id\"] = unique_id_05_ls\n",
    "\n",
    "unique_id_09_ls = []\n",
    "for index, row in mflx_labor_09.iterrows():\n",
    "  folio = int(row['trimmed_folio'])\n",
    "  id = int(row['ls'])\n",
    "  unique_id_09_ls.append(tracked[folio][id])\n",
    "mflx_labor_09[\"unique_id\"] = unique_id_09_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Total Hours Worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/2666024074.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_02['primary_hrs_yr'] = mflx_labor_02.apply(lambda row: 52 * row['tb28p'] if row['tb29_p'] == 2 else row['tb28p'] * row['tb29_p1'], axis=1)\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/2666024074.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_02['secondary_hrs_yr'] = mflx_labor_02.apply(lambda row: 52 * row['tb27s'] if row['tb29_s'] == 2 else row['tb27s'] * row['tb29_s1'], axis=1)\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/2666024074.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_02['total_hrs_yr'] = mflx_labor_02.apply(lambda row: row['primary_hrs_yr'] + row['secondary_hrs_yr'] if pd.notnull(row['secondary_hrs_yr']) else row['primary_hrs_yr'], axis=1)\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/2666024074.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_05['primary_hrs_yr'] = mflx_labor_05.apply(lambda row: 52 * row['tb28p'] if row['tb29_p'] == 2 else row['tb28p'] * row['tb29_p1'], axis=1)\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/2666024074.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_05['secondary_hrs_yr'] = mflx_labor_05.apply(lambda row: 52 * row['tb27s'] if row['tb29_s'] == 2 else row['tb27s'] * row['tb29_s1'], axis=1)\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/2666024074.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_05['total_hrs_yr'] = mflx_labor_05.apply(lambda row: row['primary_hrs_yr'] + row['secondary_hrs_yr'] if pd.notnull(row['secondary_hrs_yr']) else row['primary_hrs_yr'], axis=1)\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/2666024074.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_09['primary_hrs_yr'] = mflx_labor_09.apply(lambda row: 52 * row['tb28p'] if row['tb29_p'] == 2 else row['tb28p'] * row['tb29_p1'], axis=1)\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/2666024074.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_09['secondary_hrs_yr'] = mflx_labor_09.apply(lambda row: 52 * row['tb27s'] if row['tb29_s'] == 2 else row['tb27s'] * row['tb29_s1'], axis=1)\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/2666024074.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_09['total_hrs_yr'] = mflx_labor_09.apply(lambda row: row['primary_hrs_yr'] + row['secondary_hrs_yr'] if pd.notnull(row['secondary_hrs_yr']) else row['primary_hrs_yr'], axis=1)\n"
     ]
    }
   ],
   "source": [
    "##CODEBOOK HAS CODED WRONG, CORRECTED:\n",
    "#tb28p - hrs worked last week primary job\n",
    "#tb27s - hrs worked last week secondary job\n",
    "\n",
    "#tb29_p - primary: week/yr (1), all weeks of year (2)\n",
    "#tb29_p1 - weeks/year main\n",
    "\n",
    "#tb29_s - week/yr (1), all weeks of year (2)\n",
    "#tb29_s1 - weeks/year secondary\n",
    "\n",
    "mflx_labor_02['primary_hrs_yr'] = mflx_labor_02.apply(lambda row: 52 * row['tb28p'] if row['tb29_p'] == 2 else row['tb28p'] * row['tb29_p1'], axis=1)\n",
    "mflx_labor_02['secondary_hrs_yr'] = mflx_labor_02.apply(lambda row: 52 * row['tb27s'] if row['tb29_s'] == 2 else row['tb27s'] * row['tb29_s1'], axis=1)\n",
    "mflx_labor_02['total_hrs_yr'] = mflx_labor_02.apply(lambda row: row['primary_hrs_yr'] + row['secondary_hrs_yr'] if pd.notnull(row['secondary_hrs_yr']) else row['primary_hrs_yr'], axis=1)\n",
    "\n",
    "\n",
    "mflx_labor_05['primary_hrs_yr'] = mflx_labor_05.apply(lambda row: 52 * row['tb28p'] if row['tb29_p'] == 2 else row['tb28p'] * row['tb29_p1'], axis=1)\n",
    "mflx_labor_05['secondary_hrs_yr'] = mflx_labor_05.apply(lambda row: 52 * row['tb27s'] if row['tb29_s'] == 2 else row['tb27s'] * row['tb29_s1'], axis=1)\n",
    "mflx_labor_05['total_hrs_yr'] = mflx_labor_05.apply(lambda row: row['primary_hrs_yr'] + row['secondary_hrs_yr'] if pd.notnull(row['secondary_hrs_yr']) else row['primary_hrs_yr'], axis=1)\n",
    "\n",
    "mflx_labor_09['primary_hrs_yr'] = mflx_labor_09.apply(lambda row: 52 * row['tb28p'] if row['tb29_p'] == 2 else row['tb28p'] * row['tb29_p1'], axis=1)\n",
    "mflx_labor_09['secondary_hrs_yr'] = mflx_labor_09.apply(lambda row: 52 * row['tb27s'] if row['tb29_s'] == 2 else row['tb27s'] * row['tb29_s1'], axis=1)\n",
    "mflx_labor_09['total_hrs_yr'] = mflx_labor_09.apply(lambda row: row['primary_hrs_yr'] + row['secondary_hrs_yr'] if pd.notnull(row['secondary_hrs_yr']) else row['primary_hrs_yr'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter Those Never Work, Too Old/Young"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/3989064737.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_02['worked_over_10'] = worked_over_10_02_ls\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/3989064737.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_05['worked_over_10'] = worked_over_10_05_ls\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/3989064737.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_09['worked_over_10'] = worked_over_10_09_ls\n"
     ]
    }
   ],
   "source": [
    "worked_dict = {}\n",
    "# mflx_labor_02['trimmed_folio'] = mflx_labor_02['trimmed_folio'].astype(str)\n",
    "# mflx_labor_02['mflx_labor_02'] = mflx_labor_02['mflx_labor_02'].astype(str)\n",
    "\n",
    "# mflx_labor_02['unique_id'] = mflx_labor_02.apply(lambda row: str(row['trimmed_folio']) + str(row['ls']), axis=1)\n",
    "# mflx_labor_05['unique_id'] = mflx_labor_05.apply(lambda row: str(row['trimmed_folio']) + str(row['ls']), axis=1)\n",
    "# mflx_labor_09['unique_id'] = mflx_labor_09.apply(lambda row: str(row['trimmed_folio']) + str(row['ls']), axis=1)\n",
    "\n",
    "\n",
    "for index, row in mflx_labor_02.iterrows():\n",
    "  folio = int(row['trimmed_folio'])\n",
    "  id = int(row['ls'])\n",
    "  if row['total_hrs_yr'] > 500:\n",
    "    if folio in worked_dict:\n",
    "      worked_dict[folio][id] = 1\n",
    "    else:\n",
    "      worked_dict[folio] = {}\n",
    "      worked_dict[folio][id] = 1\n",
    "for index, row in mflx_labor_05.iterrows():\n",
    "  folio = int(row['trimmed_folio'])\n",
    "  id = int(row['ls'])\n",
    "  if row['total_hrs_yr'] > 500:\n",
    "    if folio in worked_dict:\n",
    "      worked_dict[folio][id] = 1\n",
    "    else:\n",
    "      worked_dict[folio] = {}\n",
    "      worked_dict[folio][id] = 1\n",
    "for index, row in mflx_labor_09.iterrows():\n",
    "  folio = int(row['trimmed_folio'])\n",
    "  id = int(row['ls'])\n",
    "  if row['total_hrs_yr'] > 500:\n",
    "    if folio in worked_dict:\n",
    "      worked_dict[folio][id] = 1\n",
    "    else:\n",
    "      worked_dict[folio] = {}\n",
    "      worked_dict[folio][id] = 1\n",
    "\n",
    "\n",
    "\n",
    "worked_over_10_02_ls = []\n",
    "for index, row in mflx_labor_02.iterrows():\n",
    "  folio = int(row['trimmed_folio'])\n",
    "  id = int(row['ls'])\n",
    "  if folio in worked_dict:\n",
    "    if id in worked_dict[folio]:\n",
    "      worked_over_10_02_ls.append(1)\n",
    "    else:\n",
    "      worked_over_10_02_ls.append(0)\n",
    "  else:\n",
    "    worked_over_10_02_ls.append(0)\n",
    "\n",
    "worked_over_10_05_ls = []\n",
    "for index, row in mflx_labor_05.iterrows():\n",
    "  folio = int(row['trimmed_folio'])\n",
    "  id = int(row['ls'])\n",
    "  if folio in worked_dict:\n",
    "    if id in worked_dict[folio]:\n",
    "      worked_over_10_05_ls.append(1)\n",
    "    else:\n",
    "      worked_over_10_05_ls.append(0)\n",
    "  else:\n",
    "    worked_over_10_05_ls.append(0)\n",
    "\n",
    "worked_over_10_09_ls = []\n",
    "for index, row in mflx_labor_09.iterrows():\n",
    "  folio = int(row['trimmed_folio'])\n",
    "  id = int(row['ls'])\n",
    "  if folio in worked_dict:\n",
    "    if id in worked_dict[folio]:\n",
    "      worked_over_10_09_ls.append(1)\n",
    "    else:\n",
    "      worked_over_10_09_ls.append(0)\n",
    "  else:\n",
    "    worked_over_10_09_ls.append(0)\n",
    "\n",
    "mflx_labor_02['worked_over_10'] = worked_over_10_02_ls\n",
    "mflx_labor_05['worked_over_10'] = worked_over_10_05_ls\n",
    "mflx_labor_09['worked_over_10'] = worked_over_10_09_ls\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informal vs Formal Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/107484280.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_02['informal_primary'] = mflx_labor_02.apply(lambda row: 1 if row['tb32p'] in [1,2,4, 6] else (0 if row['tb32p'] in [3,5] else np.nan), axis=1)\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/107484280.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_05['informal_primary'] = mflx_labor_05.apply(lambda row: 1 if row['tb32p'] in [1,2,4, 6] else (0 if row['tb32p'] in [3,5] else np.nan), axis=1)\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/107484280.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_09['informal_primary'] = mflx_labor_09.apply(lambda row: 1 if row['tb32p'] in [1,2,4, 6] else (0 if row['tb32p'] in [3,5] else np.nan), axis=1)\n"
     ]
    }
   ],
   "source": [
    "# mflx_labor_02['informal_primary'] = mflx_labor_02.apply(lambda row: 1 if row['tb32p'] in [1,2,4, 6] else (0 if row['tb32p'] in [3,5] else np.nan), axis=1)\n",
    "\n",
    "#what about people that switch formal\n",
    "mflx_labor_02['informal_primary'] = mflx_labor_02.apply(lambda row: 1 if row['tb32p'] in [1,2,4, 6] else (0 if row['tb32p'] in [3,5] else np.nan), axis=1)\n",
    "mflx_labor_05['informal_primary'] = mflx_labor_05.apply(lambda row: 1 if row['tb32p'] in [1,2,4, 6] else (0 if row['tb32p'] in [3,5] else np.nan), axis=1)\n",
    "mflx_labor_09['informal_primary'] = mflx_labor_09.apply(lambda row: 1 if row['tb32p'] in [1,2,4, 6] else (0 if row['tb32p'] in [3,5] else np.nan), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for Panel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/2125100756.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_02[\"period\"] = 1\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/2125100756.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_05[\"period\"] = 2\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/2125100756.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_09[\"period\"] = 3\n"
     ]
    }
   ],
   "source": [
    "mflx_labor_02[\"period\"] = 1\n",
    "mflx_labor_05[\"period\"] = 2\n",
    "mflx_labor_09[\"period\"] = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/3909849955.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_02['treatment'] = mflx_labor_02['cve_treatment']\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/3909849955.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_05['treatment'] = mflx_labor_05['cve_treatment']\n",
      "/var/folders/w4/8bdyf7817wzghq2ypzxtqpcm0000gn/T/ipykernel_26686/3909849955.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mflx_labor_09['treatment'] = mflx_labor_09['cve_treatment']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mflx_labor_02['treatment'] = mflx_labor_02['cve_treatment']\n",
    "mflx_labor_05['treatment'] = mflx_labor_05['cve_treatment']\n",
    "mflx_labor_09['treatment'] = mflx_labor_09['cve_treatment']\n",
    "\n",
    "\n",
    "mflx_labor_02['treatment'] = mflx_labor_02.apply(lambda row: 0 if row['tb32p'] in [3,5] else row['cve_treatment'], axis=1)\n",
    "mflx_labor_05['treatment'] = mflx_labor_05.apply(lambda row: 0 if row['tb32p'] in [3,5] else row['cve_treatment'], axis=1)\n",
    "mflx_labor_09['treatment'] = mflx_labor_09.apply(lambda row: 0 if row['tb32p'] in [3,5] else row['cve_treatment'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mflx_labor_merged = pd.concat([mflx_labor_02, mflx_labor_05, mflx_labor_09], ignore_index=True, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mflx_labor_merged.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export .dta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflx_labor_02.to_stata('mflx_labor_02_edited.dta')\n",
    "mflx_labor_05.to_stata('mflx_labor_05_edited.dta')\n",
    "mflx_labor_09.to_stata('mflx_labor_09_edited.dta')\n",
    "\n",
    "# mflx_labor_merged.to_stata('mflx_labor_merged.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mflx_labor_merged.to_csv('mflx_labor_merged.csv', index=False)\n",
    "# mflx_labor_merged = pd.read_csv('mflx_labor_merged.csv')\n",
    "# mflx_labor_merged.to_stata('mflx_labor_merged.dta')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
